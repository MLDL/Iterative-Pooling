{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {'Load_weights':True}\n",
    "# Loads the pretarained weights\n",
    "\n",
    "opt.update({'dataroot_1024':'data/Raise_dataset_init_crop_1024'})\n",
    "opt.update({'dataroot_none':'data/Raise_dataset_init_crop_none'})\n",
    "opt.update({'dataroot_512':'data/Raise_dataset_init_crop_512'})\n",
    "# These addresses contain the test data\n",
    "\n",
    "\n",
    "opt.update({'normalizeMean':[0.485, 0.456, 0.406]})\n",
    "opt.update({'normalizeStd':[0.229, 0.224, 0.225]}) \n",
    "# Since we use ImageNet Pre-trained weights we use these values\n",
    "\n",
    "opt.update({'batch_size':10}) \n",
    "opt.update({'sizeit':64}) # this is the actual batch size\n",
    "\n",
    "opt.update({'device':\"cuda\"})\n",
    "# change this to cpu if cuda or GPU not available\n",
    "\n",
    "# because the code has to process about 25,000 images crawling over 20GB of data on GPU the code shall\n",
    "# about 15 min to execute completely. Majority of time goes in processing the very high resolution images.\n",
    "# Remove high resolution images for speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as FF\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trns(size,opt):\n",
    "    transform_it = []\n",
    "    transform_it.append(transforms.CenterCrop(size))\n",
    "    \n",
    "    transform_it.append(transforms.ToTensor())\n",
    "    transform_it.append(transforms.Normalize(opt['normalizeMean'], opt['normalizeStd']))\n",
    "    trns=transforms.Compose(transform_it)\n",
    "    return trns\n",
    "\n",
    "trns128 = make_trns(128,opt)\n",
    "trns256 = make_trns(256,opt)\n",
    "trns512 = make_trns(512,opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data(Dataset):\n",
    "    \"\"\"Loads the Data.\"\"\"\n",
    "\n",
    "    def __init__(self, opt, transform=None, whichsize=None):\n",
    "        \n",
    "        if whichsize=='64':\n",
    "            self.root_dir = opt['dataroot_512']\n",
    "        elif whichsize=='128':\n",
    "            self.root_dir = opt['dataroot_1024']\n",
    "        else:\n",
    "            self.root_dir = opt['dataroot_none']\n",
    "        \n",
    "        self.transform = transform\n",
    "            \n",
    "        tmp = sorted(os.walk(os.path.join(self.root_dir,'90_06/test')))\n",
    "        self.train1files = sorted(tmp[0][2])\n",
    "\n",
    "        tmp = sorted(os.walk(os.path.join(self.root_dir,'90_08/test')))\n",
    "        self.train2files = sorted(tmp[0][2])\n",
    "\n",
    "        tmp = sorted(os.walk(os.path.join(self.root_dir,'90_1/test')))\n",
    "        self.train3files = sorted(tmp[0][2])\n",
    "\n",
    "        tmp = sorted(os.walk(os.path.join(self.root_dir,'90_12/test')))\n",
    "        self.train4files = sorted(tmp[0][2])\n",
    "\n",
    "        tmp = sorted(os.walk(os.path.join(self.root_dir,'90_14/test')))\n",
    "        self.train5files = sorted(tmp[0][2])\n",
    "                \n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.train1files),len(self.train2files),len(self.train3files),\n",
    "                   len(self.train4files),len(self.train5files))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            \n",
    "        \n",
    "        path = os.path.join(self.root_dir,'90_06/test',self.train1files[idx])\n",
    "        image1 = Image.open(path).convert('RGB')\n",
    "\n",
    "        path = os.path.join(self.root_dir,'90_08/test',self.train2files[idx])\n",
    "        image2 = Image.open(path).convert('RGB')\n",
    "\n",
    "        path = os.path.join(self.root_dir,'90_1/test',self.train3files[idx])\n",
    "        image3 = Image.open(path).convert('RGB')\n",
    "\n",
    "        path = os.path.join(self.root_dir,'90_12/test',self.train4files[idx])\n",
    "        image4 = Image.open(path).convert('RGB')\n",
    "\n",
    "        path = os.path.join(self.root_dir,'90_14/test',self.train5files[idx])\n",
    "        image5 = Image.open(path).convert('RGB')\n",
    "        \n",
    "        image1 = self.transform(image1)\n",
    "        image2 = self.transform(image2)\n",
    "        image3 = self.transform(image3)\n",
    "        image4 = self.transform(image4)\n",
    "        image5 = self.transform(image5)\n",
    "        \n",
    "        \n",
    "        return {'image1': image1, 'image2': image2, 'image3': image3, 'image4': image4, 'image5': image5, \n",
    "                'label1':0, 'label2':1, 'label3':2, 'label4':3, 'label5':4 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_test64 = get_data(opt, trns128, '64') # base resolution: 512, patch size: 128\n",
    "\n",
    "opt.update({'dataloader_test512v128':DataLoader(data_test64, batch_size=opt['batch_size'],\n",
    "                       shuffle=True, num_workers=1, pin_memory=False)})\n",
    "\n",
    "data_test64 = get_data(opt, trns128, '128') # base resolution: 1024, patch size: 128\n",
    "\n",
    "opt.update({'dataloader_test1024v128':DataLoader(data_test64, batch_size=opt['batch_size'],\n",
    "                       shuffle=True, num_workers=1, pin_memory=False)})\n",
    "\n",
    "data_test64 = get_data(opt, trns256, '128') # base resolution: 1024, patch size: 256\n",
    "\n",
    "opt.update({'dataloader_test1024v256':DataLoader(data_test64, batch_size=opt['batch_size'],\n",
    "                       shuffle=True, num_workers=1, pin_memory=False)})\n",
    "\n",
    "data_test64 = get_data(opt, trns256, '512') # base resolution: >1024, patch size: 256\n",
    "\n",
    "opt.update({'dataloader_test3000v256':DataLoader(data_test64, batch_size=opt['batch_size'],\n",
    "                       shuffle=True, num_workers=1, pin_memory=False)})\n",
    "\n",
    "data_test64 = get_data(opt, trns512, '512') # base resolution: >1024, patch size: 512\n",
    "\n",
    "opt.update({'dataloader_test3000v512':DataLoader(data_test64, batch_size=opt['batch_size'],\n",
    "                       shuffle=True, num_workers=1, pin_memory=False)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_resnet, self).__init__()\n",
    "        \n",
    "        model_ft = models.resnet18(pretrained=True)        \n",
    "        self.feat1 = nn.Sequential(*list(model_ft.children())[:6])\n",
    "        self.feat2 = nn.Sequential(*list(model_ft.children())[6:8])\n",
    "        \n",
    "        self.rel = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.fc = nn.Linear(512, 5)\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1, bias=True)\n",
    "        self.bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.roi1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        \n",
    "    def forward(self,out):\n",
    "        \n",
    "        out = self.bn(self.conv(self.feat1(out)))\n",
    "        if out.size()[2]==8:\n",
    "            out = self.roi1(out)\n",
    "        if out.size()[2]==16:\n",
    "            out = self.roi1(self.conv(out))\n",
    "        if out.size()[2]==32:\n",
    "            out = self.roi1(self.conv(self.conv(out)))\n",
    "            \n",
    "        out = self.feat2(out)\n",
    "        out = out.view(-1,512)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class common_functions():\n",
    "    \n",
    "    def __init__(self, opt):\n",
    "        \n",
    "        self.opt = opt\n",
    "        \n",
    "        \n",
    "        self.best_test_acc = 0\n",
    "        self.lowest_train_err = 100\n",
    "        self.device = torch.device(self.opt['device'])\n",
    "        self.test_acc = 0\n",
    "        self.test_acc = 0\n",
    "        self.count_save = 0\n",
    "        self.step_count = 0\n",
    "        \n",
    "        \n",
    "        model = my_resnet()\n",
    "        self.model = model.to(self.device)\n",
    "        print(self.model)\n",
    "        print(next(self.model.parameters()).is_cuda)\n",
    "          \n",
    "        \n",
    "        if opt['Load_weights']:\n",
    "            checkpoint = torch.load('BestModel')\n",
    "            self.model.load_state_dict(checkpoint['model'])\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def find_acc(self, loader):\n",
    "        \n",
    "        correct1 = 0\n",
    "        total1 = 0\n",
    "        correct2 = 0\n",
    "        total2 = 0\n",
    "        correct3 = 0\n",
    "        total3 = 0\n",
    "        correct4 = 0\n",
    "        total4 = 0\n",
    "        correct5 = 0\n",
    "        total5 = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.model.eval()        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i,images in enumerate(loader):\n",
    "                \n",
    "                images['image1'] = images['image1'].to(self.device)\n",
    "                images['image2'] = images['image2'].to(self.device)\n",
    "                images['image3'] = images['image3'].to(self.device)\n",
    "                images['image4'] = images['image4'].to(self.device)\n",
    "                images['image5'] = images['image5'].to(self.device)\n",
    "                \n",
    "                images['label1'] = images['label1'].to(self.device)\n",
    "                images['label2'] = images['label2'].to(self.device)\n",
    "                images['label3'] = images['label3'].to(self.device)\n",
    "                images['label4'] = images['label4'].to(self.device)\n",
    "                images['label5'] = images['label5'].to(self.device)\n",
    "                \n",
    "                \n",
    "                out1 = self.model(images['image1'])\n",
    "                \n",
    "                out2 = self.model(images['image2'])\n",
    "                \n",
    "                out3 = self.model(images['image3'])\n",
    "                \n",
    "                out4 = self.model(images['image4'])\n",
    "                \n",
    "                out5 = self.model(images['image5'])\n",
    "                \n",
    "                               \n",
    "                _, predicted1 = torch.max(out1.data, 1)\n",
    "                _, predicted2 = torch.max(out2.data, 1)\n",
    "                _, predicted3 = torch.max(out3.data, 1)\n",
    "                _, predicted4 = torch.max(out4.data, 1)\n",
    "                _, predicted5 = torch.max(out5.data, 1)\n",
    "                \n",
    "                total1 += len(images['label1'])\n",
    "                #print(type(totalA))\n",
    "                total2 += len(images['label2'])\n",
    "                #print(totalB)\n",
    "                total3 += len(images['label3'])\n",
    "                #print(type(totalA))\n",
    "                total4 += len(images['label4'])\n",
    "                #print(totalB)\n",
    "                total5 += len(images['label5'])\n",
    "                #print(totalB)\n",
    "                \n",
    "                correct1 += (predicted1 == images['label1']).sum().item()\n",
    "                # this just a int not even tensor\n",
    "                correct2 += (predicted2 == images['label2']).sum().item()\n",
    "                correct3 += (predicted3 == images['label3']).sum().item()\n",
    "                # this just a int not even tensor\n",
    "                correct4 += (predicted4 == images['label4']).sum().item()\n",
    "                correct5 += (predicted5 == images['label5']).sum().item()\n",
    "                \n",
    "        #print('end of enumeration')\n",
    "        test_acc1 = 100 * float(correct1) / float(total1)\n",
    "        \n",
    "        #print(test_accA.type())\n",
    "        test_acc2 = 100 * float(correct2) / float(total2)\n",
    "        \n",
    "        test_acc3 = 100 * float(correct3) / float(total3)\n",
    "        \n",
    "        #print(test_accA.type())\n",
    "        test_acc4 = 100 * float(correct4) / float(total4)\n",
    "        \n",
    "        test_acc5 = 100 * float(correct5) / float(total5)\n",
    "        \n",
    "        test_acc = (test_acc1 + test_acc2+ test_acc3+ test_acc4 + test_acc5)/5\n",
    "        \n",
    "        \n",
    "        return total1, total2, total3, total4, total5, correct1, correct2, correct3, correct4, correct5, test_acc\n",
    "        \n",
    "        \n",
    "    \n",
    "                \n",
    "    \n",
    "    def optimize_parameters(self):\n",
    "            \n",
    "        \n",
    "            \n",
    "        loader = self.opt['dataloader_test512v128']\n",
    "        total1, total2, total3, total4, total5, correct1, correct2, correct3, correct4, correct5, test_acc = self.find_acc(loader)\n",
    "        \n",
    "\n",
    "        print('Image size 512x512 with patch size 128x128')\n",
    "\n",
    "        print('Resampling Factor 0.6:{}/{} 0.8:{}/{} 1:{}/{} 1.2:{}/{} 1.4:{}/{}'.format(correct1, total1,\n",
    "                                                                  correct2, total2,\n",
    "                                                                  correct3, total3,\n",
    "                                                                  correct4, total4,\n",
    "                                                                  correct5, total5))\n",
    "\n",
    "        ###########################################\n",
    "\n",
    "        loader = self.opt['dataloader_test1024v128']\n",
    "        total1, total2, total3, total4, total5, correct1, correct2, correct3, correct4, correct5, test_acc = self.find_acc(loader)            \n",
    "\n",
    "        \n",
    "\n",
    "        print('\\n Image size 1024x1024 with patch size 128x128')\n",
    "        \n",
    "\n",
    "        print('Resampling Factor 0.6:{}/{} 0.8:{}/{} 1:{}/{} 1.2:{}/{} 1.4:{}/{}'.format(correct1, total1,\n",
    "                                                                  correct2, total2,\n",
    "                                                                  correct3, total3,\n",
    "                                                                  correct4, total4,\n",
    "                                                                  correct5, total5))\n",
    "\n",
    "        ###########################################\n",
    "\n",
    "        loader = self.opt['dataloader_test1024v256']\n",
    "        total1, total2, total3, total4, total5, correct1, correct2, correct3, correct4, correct5, test_acc = self.find_acc(loader)            \n",
    "\n",
    "\n",
    "        print('\\n Image size 1024x1024 with patc size 256x256')\n",
    "        \n",
    "\n",
    "        print('Resampling Factor 0.6:{}/{} 0.8:{}/{} 1:{}/{} 1.2:{}/{} 1.4:{}/{}'.format(correct1, total1,\n",
    "                                                                  correct2, total2,\n",
    "                                                                  correct3, total3,\n",
    "                                                                  correct4, total4,\n",
    "                                                                  correct5, total5))\n",
    "\n",
    "        ##############################\n",
    "\n",
    "        loader = self.opt['dataloader_test3000v256']\n",
    "        total1, total2, total3, total4, total5, correct1, correct2, correct3, correct4, correct5, test_acc = self.find_acc(loader)            \n",
    "\n",
    "        print('\\n Image sizes greater than 1024x1024 with patch size 256x256')\n",
    "        \n",
    "\n",
    "        print('Resampling Factor 0.6:{}/{} 0.8:{}/{} 1:{}/{} 1.2:{}/{} 1.4:{}/{}'.format(correct1, total1,\n",
    "                                                                  correct2, total2,\n",
    "                                                                  correct3, total3,\n",
    "                                                                  correct4, total4,\n",
    "                                                                  correct5, total5))\n",
    "        ##############################\n",
    "\n",
    "        loader = self.opt['dataloader_test3000v512']\n",
    "        total1, total2, total3, total4, total5, correct1, correct2, correct3, correct4, correct5, test_acc = self.find_acc(loader)           \n",
    "\n",
    "        print('\\n Image sizes greater than 1024x1024 with patch size 512x512')\n",
    "\n",
    "        print('Resampling Factor 0.6:{}/{} 0.8:{}/{} 1:{}/{} 1.2:{}/{} 1.4:{}/{}'.format(correct1, total1,\n",
    "                                                                  correct2, total2,\n",
    "                                                                  correct3, total3,\n",
    "                                                                  correct4, total4,\n",
    "                                                                  correct5, total5))\n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_resnet(\n",
      "  (feat1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feat2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rel): ReLU(inplace=True)\n",
      "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (roi1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "True\n",
      "Image size 512x512 with patch size 128x128\n",
      "Resampling Factor 0.6:968/1001 0.8:976/1001 1:961/1001 1.2:935/1001 1.4:936/1001\n",
      "\n",
      " Image size 1024x1024 with patch size 128x128\n",
      "Resampling Factor 0.6:979/1001 0.8:344/1001 1:961/1001 1.2:13/1001 1.4:12/1001\n",
      "\n",
      " Image size 1024x1024 with patc size 256x256\n",
      "Resampling Factor 0.6:253/1001 0.8:989/1001 1:995/1001 1.2:997/1001 1.4:952/1001\n",
      "\n",
      " Image sizes greater than 1024x1024 with patch size 256x256\n",
      "Resampling Factor 0.6:991/1001 0.8:959/1001 1:992/1001 1.2:434/1001 1.4:392/1001\n",
      "\n",
      " Image sizes greater than 1024x1024 with patch size 512x512\n",
      "Resampling Factor 0.6:143/1001 0.8:21/1001 1:994/1001 1.2:963/1001 1.4:999/1001\n"
     ]
    }
   ],
   "source": [
    "gan_model = common_functions(opt)\n",
    "gan_model.optimize_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### So with base-size vs patch size selection criteria given in paper [Refer table titled 'Patch sizes for the proposed IPN and BN.'] the accuracy is\n",
    "\n",
    "Image size 512x512 with patch size 128x128\n",
    "Resampling Factor 0.6:968/1001 0.8:976/1001 1:961/1001 1.2:935/1001 1.4:936/1001\n",
    "\n",
    " Image size 1024x1024 with patch size 128x128\n",
    "Resampling Factor 0.6:979/1001\n",
    "\n",
    " Image size 1024x1024 with patc size 256x256\n",
    "Resampling Factor 0.8:989/1001 1:995/1001 1.2:997/1001\n",
    "\n",
    " Image sizes greater than 1024x1024 with patch size 256x256\n",
    "Resampling Factor 0.6:991/1001 0.8:959/1001 1:992/1001\n",
    "\n",
    " Image sizes greater than 1024x1024 with patch size 512x512\n",
    "Resampling Factor 1:994/1001 1.2:963/1001 1.4:999/1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
